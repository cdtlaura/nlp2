{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhENwYYKWzJhNHJrG7RApW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdtlaura/nlp2/blob/main/Final_project_Document_Summarization_and_Translation_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Document Summarization and Translation App\". This app summarizes lengthy documents and translates the summaries into multiple languages (e.g., French, Spanish, Chinese). Businesses could use it for:\n",
        "Quickly understanding key points of reports.\n",
        "Communicating summaries to international teams."
      ],
      "metadata": {
        "id": "NEjjJI-qQsB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified Application Plan\n",
        "\n",
        "Input: A user uploads a document (e.g., Word .docx) via a file uploader.\n",
        "\n",
        "Processing:\n",
        "Extract content from the uploaded document.\n",
        "Summarize the document using an LLM (Together AI in this case).\n",
        "\n",
        "Translate the summary into multiple languages (e.g., French, Spanish, Chinese).\n",
        "\n",
        "Output:\n",
        "Display:\n",
        "The original summary.\n",
        "\n",
        "Translations of the summary.\n",
        "\n",
        "Optionally save the summary and translations as a downloadable file (e.g., PDF or .txt)."
      ],
      "metadata": {
        "id": "0je3iIEOSCAL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of the Workflow\n",
        "Upload Document:\n",
        "\n",
        "\n",
        "Uses Colab's files.upload() to allow users to upload a Word document.\n",
        "\n",
        "Extract Content:\n",
        "\n",
        "\n",
        "The uploaded document is read and its text content is extracted using the Docx2txtLoader from langchain_community.\n",
        "\n",
        "Summarize Content:\n",
        "\n",
        "\n",
        "The full document content is summarized using Together AI's meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo model.\n",
        "The prompt explicitly requests a detailed and comprehensive summary.\n",
        "\n",
        "Translate Summary:\n",
        "\n",
        "\n",
        "Translations are handled by MarianMT models for French, Spanish, and Chinese.\n",
        "\n",
        "Display Results:\n",
        "\n",
        "\n",
        "The original summary and translations are displayed in Markdown format for readability.\n",
        "\n",
        "Save Results:\n",
        "\n",
        "\n",
        "The summary and translations are saved to a .txt file, which is then made available for download."
      ],
      "metadata": {
        "id": "4cc4kFNqSC_M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJe9WDbTnDCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8ae746-e3c7-4d44-9f56-bbf07c59622c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/70.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/4.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install together -qqq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_together python-dotenv langchain-community langchain youtube_transcript_api pytube numpy -qqq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u_eN2SDnNde",
        "outputId": "65221582-ca2c-4f6a-c96c-5318f897f3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.3/622.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  docx2txt -qqq"
      ],
      "metadata": {
        "id": "-kxvbItDozlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4103635f-251b-48a1-bd33-243d54797092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-together --upgrade -qqq\n"
      ],
      "metadata": {
        "id": "ppaNDHmTzUlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from IPython.display import Markdown, display\n",
        "import os\n",
        "from together import Together\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "NYb9mJfLNKgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your API key as an environment variable\n",
        "os.environ[\"TOGETHER_API_KEY\"] = \"\"\n",
        "client = Together()"
      ],
      "metadata": {
        "id": "EwZhhV6bnIN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the Word document\n",
        "loader = Docx2txtLoader(\"/content/Computer Vision10.docx\")\n",
        "data = loader.load()\n",
        "\n",
        "# Step 2: Extract content from the document\n",
        "document_content = \" \".join([doc.page_content for doc in data])\n",
        "\n",
        "# Step 3: Query the LLM for a summary\n",
        "stream = client.chat.completions.create(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    messages=[{\"role\": \"user\", \"content\": f\"Please summarize the following document:\\n\\n{document_content}\"}],\n",
        "    stream=True,\n",
        ")\n",
        "\n",
        "# Step 4: Collect the streamed summary (no printing here)\n",
        "summary_text = \"\"  # Initialize an empty string to store the final summary\n",
        "for chunk in stream:\n",
        "    chunk_content = chunk.choices[0].delta.content or \"\"\n",
        "    summary_text += chunk_content  # Concatenate the chunk content to build the summary\n",
        "\n",
        "# Step 5: Display the summary only once\n",
        "print(\"Summary:\")\n",
        "display(Markdown(summary_text))\n",
        "\n",
        "# Step 6: Load MarianMT models and tokenizers for multiple translations\n",
        "translation_models = {\n",
        "    \"French\": {\n",
        "        \"model\": MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\"),\n",
        "        \"tokenizer\": MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\"),\n",
        "    },\n",
        "    \"Spanish\": {\n",
        "        \"model\": MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\"),\n",
        "        \"tokenizer\": MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\"),\n",
        "    },\n",
        "    \"Chinese\": {\n",
        "        \"model\": MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-zh\"),\n",
        "        \"tokenizer\": MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-zh\"),\n",
        "    },\n",
        "}\n",
        "\n",
        "# Step 7: Function to split text into smaller chunks\n",
        "def split_text(text, max_chunk_size=512):\n",
        "    \"\"\"\n",
        "    Splits text into smaller chunks that fit within the token limit.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for word in words:\n",
        "        current_chunk.append(word)\n",
        "        if len(\" \".join(current_chunk)) > max_chunk_size:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "\n",
        "    if current_chunk:  # Add any remaining words as the last chunk\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Step 8: Function to translate text in chunks\n",
        "def translate_text_in_chunks(text, model, tokenizer, max_tokens=512):\n",
        "    \"\"\"\n",
        "    Translates large text by splitting it into chunks that fit within the token limit.\n",
        "    \"\"\"\n",
        "    chunks = split_text(text, max_chunk_size=max_tokens)  # Split text into chunks\n",
        "    translated_chunks = []\n",
        "\n",
        "    for chunk in chunks:\n",
        "        input_ids = tokenizer.encode(chunk, return_tensors=\"pt\", truncation=True)\n",
        "        output_ids = model.generate(input_ids, max_length=max_tokens, num_beams=4)\n",
        "        translated_chunks.append(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n",
        "\n",
        "    return \" \".join(translated_chunks)\n",
        "\n",
        "# Step 9: Translate the LLM summary into multiple languages\n",
        "translations = {}\n",
        "for language, resources in translation_models.items():\n",
        "    translations[language] = translate_text_in_chunks(summary_text, resources[\"model\"], resources[\"tokenizer\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "qExtMGCKNVMj",
        "outputId": "6746223e-8c97-4bfd-de17-cf2cb89f75e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The document is an introduction to image smoothing and thresholding techniques using OpenCV, a widely used open-source computer vision library. The authors, Laura Castillo and Yamil Guevara, provide an overview of the following techniques:\n\n1. **Averaging Smoothing**: This technique reduces image noise by calculating the mean of pixel values within a kernel. It is simple and effective, but can lead to a blurred effect.\n2. **Gaussian Blurring**: This technique improves on averaging smoothing by applying a Gaussian function to the pixels, emphasizing the central pixels in the kernel area. It is useful for reducing Gaussian noise in images.\n3. **Median Blurring**: This technique is ideal for removing \"salt-and-pepper\" noise from images by calculating the median of all pixels within a kernel. It preserves edges and reduces the impact of outliers.\n4. **Bilateral Filtering**: This technique smooths an image while preserving its edges by considering both the spatial distance and intensity difference of pixels in the kernel.\n5. **Simple Thresholding**: This technique separates the foreground from the background by setting pixel values above or below a certain threshold to a maximum or minimum intensity.\n6. **Adaptive Thresholding**: This technique extends simple thresholding by allowing the threshold value to vary across different regions of the image, making it effective for images with varying illumination.\n\nThe authors explain how to use OpenCV functions to implement these techniques, including:\n\n* `cv.blur()` and `cv.boxFilter()` for averaging smoothing\n* `cv.GaussianBlur()` for Gaussian blurring\n* `cv.medianBlur()` for median blurring\n* `cv.bilateralFilter()` for bilateral filtering\n* `cv.threshold()` for simple thresholding\n* `cv.adaptiveThreshold()` for adaptive thresholding\n\nThe document concludes that mastering these fundamental techniques is crucial for developing sophisticated computer vision applications, demonstrating the utility and flexibility of OpenCV in handling diverse vision tasks."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Display the translated summaries\n",
        "print(\"\\nTranslated Summaries:\")\n",
        "for language, translated_text in translations.items():\n",
        "    print(f\"\\nTranslated Summary in {language}:\")\n",
        "    display(Markdown(translated_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "LkYEDGhDPzqR",
        "outputId": "f44e16ad-89ab-47d2-bea7-0413d2b18baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Translated Summaries:\n",
            "\n",
            "Translated Summary in French:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Les auteurs, Laura Castillo et Yamil Guevara, donnent un aperçu des techniques suivantes : 1. **Averaging Smoothing**: Cette technique réduit le bruit d'image en calculant la moyenne des valeurs de pixel à l'intérieur d'un noyau. Elle est simple et efficace, ce qui en fait un point de départ commun pour la réduction du bruit d'image. 2. **Gaussian Blurring**: Cette technique améliore la moyenne par l'utilisation de l'image. Il est utile pour réduire le bruit gaussien dans les images et est largement utilisé dans les étapes de prétraitement pour la détection des bords et la segmentation de l'image. 3. **Blurring Median**: Cette technique est idéale pour éliminer le bruit \"sel et poivre\" des images en calculant la médiane de tous les pixels à l'intérieur d'un noyau. Il préserve les bords et réduit l'impact des valeurs aberrantes, ce qui le rend utile pour les applications où le maintien des détails structuraux est 4. ** Filtrage bilatéral**: Cette technique lisse une image tout en préservant ses bords en tenant compte à la fois de la distance spatiale et de la différence d'intensité des pixels dans le noyau. Elle est intensive par calcul mais convient à des applications comme la reconnaissance faciale et l'extraction des fonctionnalités. 5. **Simple Thresholding**: Cette technique sépare le premier plan de l'arrière-plan en fixant des valeurs de pixel au-dessus ou au-dessous d'un certain seuil à une intensité maximale ou minimale. 6. **Thresholding adaptatif**: Cette technique étend le concept de seuil simple en permettant à la valeur seuil de varier d'une région à l'autre de l'image. Elle est efficace pour les images avec un éclairage variable et fournit une meilleure précision de segmentation par rapport au seuil simple. Les auteurs concluent qu'OpenCV fournit un ensemble polyvalent d'outils pour le lissage et le seuil d'image, chacun avec La maîtrise de ces techniques fondamentales est cruciale pour développer des applications de vision informatique sophistiquées, démontrant l'utilité et la flexibilité d'OpenCV dans la gestion de diverses tâches de vision."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Translated Summary in Spanish:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "El documento es una introducción a las técnicas de suavizado y umbralado de imágenes utilizando OpenCV, una biblioteca de visión de código abierto ampliamente utilizada. Los autores, Laura Castillo y Yamil Guevara, proporcionan una visión general de las siguientes técnicas: 1. **Average Smoothing**: Esta técnica reduce el ruido de la imagen calculando la media de los valores de píxeles dentro de un núcleo. Es simple y eficaz, lo que lo convierte en un punto de partida común para la reducción del ruido de imagen. 2. **Gaussian Blurring**: Esta técnica mejora en el promedio por aplicación de una función gaussiana a los píxeles, haciendo hincapié en los píxeles centrales en el área del núcleo. Es útil para reducir el ruido gaussiano en imágenes y se utiliza ampliamente en los pasos de preprocesamiento para la detección de bordes y la segmentación de imágenes. 3. **Blurring medio**: Esta técnica es ideal para eliminar el ruido \"sal y pimienta\" de las imágenes mediante el cálculo de la mediana de todos los píxeles dentro de un núcleo. 4. ** Filtrado bilateral**: Esta técnica suaviza una imagen al tiempo que preserva sus bordes considerando tanto la distancia espacial como la diferencia de intensidad de píxeles en el núcleo. Es computacionalmente intensiva pero adecuada para aplicaciones como reconocimiento facial y extracción de características. 5. ** Sencillo Thresholding**: Esta técnica separa el primer plano del fondo estableciendo valores de píxeles por encima o por debajo de un determinado umbral a una intensidad máxima o mínima. Es ideal para imágenes consistentes. La iluminación y es útil en escenarios donde el objetivo es crear una representación binaria de una imagen. 6. **Adaptive Thresholding**: Esta técnica amplía el concepto de umbral simple permitiendo que el valor de umbral varíe entre diferentes regiones de la imagen. Es eficaz para imágenes con iluminación variable y proporciona una mejor precisión de segmentación en comparación con el umbral simple. Los autores concluyen que OpenCV proporciona un conjunto versátil de herramientas para suavizar y umbralizar la imagen, cada una con Dominar estas técnicas fundamentales es crucial para desarrollar aplicaciones sofisticadas de visión por ordenador, demostrando la utilidad y flexibilidad de OpenCV en el manejo de diversas tareas de visión."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Translated Summary in Chinese:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "本文介绍使用开放源开源计算机视觉图书馆OpenCV的图像平滑和临界技术。作者Laura Castillo和Yamil Guevara概述了以下技术:1. ** 虚拟平滑**:这种技术通过计算内核内像素值的平均值来减少图像噪音。它简单而有效,使它成为减少图像噪音的共同起点。 ** Gaussian Blurring**:这种技术在平均率方面有所改进。 a Gaussian 函数应用于像素, 突出内核区域的核心像素。 它有助于减少图像中的高萨噪音, 并广泛用于边缘探测和图像分割的预处理步骤。 ** ** Median Blurring **: 这一技术最理想的办法是通过计算内核内核中所有像素的中位数,从图像中去除“ 盐和比珀” 噪音。 它保存边缘并减少外部线的影响, 从而在保持结构细节时对应用程序有用。 4. ** 双边过滤**:这一技术既考虑到内核像素的空间距离和强度差异,又考虑到内核中像素的空间距离和强度差异,使图像在保持边缘的同时平滑,它具有计算强度,但适合面部识别和特征提取等应用。 6 ** 加速推进**:这一技术扩大了简单门槛值的概念,允许图像在不同区域之间的临界值变化,从而扩展了简单门槛值的概念。该技术对不同照明度的图像有效,与简单门槛值相比,提供了更好的分解准确度。作者得出结论,OpenCV为图像平滑和阈值提供了一套多功能工具,每个工具都有: 掌握这些基本技术对于开发先进的计算机视觉应用至关重要,可以证明开放文化电视公司在处理各种视觉任务时的效用和灵活性。"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\"\n",
        "### Business Use Case:\n",
        "This application addresses the need for quick and efficient processing of lengthy documents in multinational organizations. By summarizing and translating business reports, research papers, and other documents, it enhances global communication and reduces manual workload.\n",
        "\n",
        "### Business Value:\n",
        "The tool enables businesses to save time, improve productivity, and foster collaboration across language barriers. By automating summarization and translation, organizations can focus on strategic decision-making while ensuring all team members have access to the same information, regardless of language.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "UqLAHfgQS3kz"
      }
    }
  ]
}