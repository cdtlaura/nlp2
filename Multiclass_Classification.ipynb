{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY0dBdxTHljLHQEi3s2Eui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdtlaura/nlp2/blob/main/Multiclass_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Explore the Data"
      ],
      "metadata": {
        "id": "l1lIYibrLFEM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_8pAD8P_16B",
        "outputId": "ce209796-5806-47ea-c7c0-36d9c49171e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
            "0  28395    610.291       208.178117       173.888747      1.197191   \n",
            "1  28734    638.018       200.524796       182.734419      1.097356   \n",
            "2  29380    624.110       212.826130       175.931143      1.209713   \n",
            "3  30008    645.884       210.557999       182.516516      1.153638   \n",
            "4  30140    620.134       201.847882       190.279279      1.060798   \n",
            "\n",
            "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
            "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
            "1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
            "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
            "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
            "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
            "\n",
            "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
            "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
            "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
            "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
            "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
            "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  \n",
            "Index(['Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength',\n",
            "       'AspectRation', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent',\n",
            "       'Solidity', 'roundness', 'Compactness', 'ShapeFactor1', 'ShapeFactor2',\n",
            "       'ShapeFactor3', 'ShapeFactor4', 'Class'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('/content/Dry_Bean_Dataset.xlsx', sheet_name='Dry_Beans_Dataset')\n",
        "\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n",
        "# Display the column names\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Data"
      ],
      "metadata": {
        "id": "czCnf1J3LDHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Handle missing values if necessary\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate input features and target variable\n",
        "X = df.drop(columns=['Class'])  # 'Class' is the target column\n",
        "y = df['Class'].values\n",
        "\n",
        "# Encode the target variable y (Class)\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)  # Converts the three Class types into 0, 1, 3, 4, 5 ,6 or 7\n",
        "\n",
        "# Check the number of features\n",
        "n_features = X.shape[1]"
      ],
      "metadata": {
        "id": "yVn8YQHu_8zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data into Train and Test Sets"
      ],
      "metadata": {
        "id": "HF90iwGeK_e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
      ],
      "metadata": {
        "id": "145wL-STAAVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Model for Multiclass Classification"
      ],
      "metadata": {
        "id": "FqBdTc9CK564"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(7, activation='softmax'))  # Changed to 7 neurons to match 7 classes (0-6) (Seker, Barbunya, Bombay, Cali, Dermosan, Horoz and Sira)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljN7Yj8kFRYS",
        "outputId": "d5e4f663-75c9-4986-f8ad-107a9c04a336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize the Data"
      ],
      "metadata": {
        "id": "kuwrRP0CKmbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "pWVlH_T9J6Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Early Stopping\n",
        "Early stopping helps prevent overfitting by stopping training once the model performance stops improving on the validation set:"
      ],
      "metadata": {
        "id": "X9egxad_KgOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=16, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqfpjfHjKdal",
        "outputId": "f69d5ebf-70da-4fed-966b-071df393a857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.1396 - val_accuracy: 0.9287 - val_loss: 0.2356\n",
            "Epoch 2/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1462 - val_accuracy: 0.9304 - val_loss: 0.2303\n",
            "Epoch 3/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1521 - val_accuracy: 0.9282 - val_loss: 0.2237\n",
            "Epoch 4/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9393 - loss: 0.1552 - val_accuracy: 0.9298 - val_loss: 0.2230\n",
            "Epoch 5/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.1513 - val_accuracy: 0.9282 - val_loss: 0.2329\n",
            "Epoch 6/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9419 - loss: 0.1512 - val_accuracy: 0.9211 - val_loss: 0.2369\n",
            "Epoch 7/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9433 - loss: 0.1487 - val_accuracy: 0.9260 - val_loss: 0.2366\n",
            "Epoch 8/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9462 - loss: 0.1392 - val_accuracy: 0.9282 - val_loss: 0.2291\n",
            "Epoch 9/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.1484 - val_accuracy: 0.9282 - val_loss: 0.2341\n",
            "Epoch 10/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1405 - val_accuracy: 0.9249 - val_loss: 0.2384\n",
            "Epoch 11/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1573 - val_accuracy: 0.9227 - val_loss: 0.2440\n",
            "Epoch 12/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1486 - val_accuracy: 0.9271 - val_loss: 0.2341\n",
            "Epoch 13/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1505 - val_accuracy: 0.9293 - val_loss: 0.2346\n",
            "Epoch 14/300\n",
            "\u001b[1m456/456\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1460 - val_accuracy: 0.9232 - val_loss: 0.2358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78430f1ce230>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Accuracy: %.3f' % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xT2hPtgAMOP",
        "outputId": "359cb765-9a96-4c22-92f5-ce1475f212f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction\n",
        "import numpy as np\n",
        "\n",
        "sample = np.array([[28395, 610.291, 208.178117, 173.888747041636, 1.19719142411602, 0.549812187138347, 28715, 190.141097274511, 0.763922518159806, 0.988855998607, 0.958027126250128, 0.913357754795763, 0.00733150613518321, 0.00314728916733569, 0.834222388245556, 0.998723889013168]])  # Example input for a new Class\n",
        "prediction = model.predict(sample)\n",
        "\n",
        "# Convert the prediction probabilities into a class label\n",
        "predicted_class = np.argmax(prediction, axis=1)\n",
        "print('Predicted class:', predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqWDkdM7AQiC",
        "outputId": "f29dd651-1f45-4e1e-bf7d-2d7b28cf114a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "Predicted class: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the mapping of encoded labels\n",
        "for idx, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{label}: {idx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCQmBOaSIy8D",
        "outputId": "b8978d1a-d1bb-4e6a-e03e-da57ba9d0edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BARBUNYA: 0\n",
            "BOMBAY: 1\n",
            "CALI: 2\n",
            "DERMASON: 3\n",
            "HOROZ: 4\n",
            "SEKER: 5\n",
            "SIRA: 6\n"
          ]
        }
      ]
    }
  ]
}